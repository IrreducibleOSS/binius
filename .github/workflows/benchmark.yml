name: Benchmark
run-name: >-
    ${{ github.event_name == 'workflow_dispatch' &&
        format('Benchmark: "{0}" (on-demand)', inputs.benchmark) ||
        format('Benchmark: "{0}" (commit)', github.event.head_commit.message)
    }}

on:
    push:
        branches: [main]
    workflow_dispatch: # Manual trigger
        inputs:
            benchmark:
                description: "Benchmark to run (choose a specific benchmark or 'all')"
                type: choice
                options: [all, keccakf, groestl, b32_mul, u32_add, u32_mul_gkr, xor, and, or] # Example options; replace with actual benchmark names
                default: all
            publish_results:
                description: "Publish results to Bencher (any branch) and GH Pages (main branch only)"
                type: boolean
                default: false
jobs:
    #
    # Prepare
    #
    prepare:
        runs-on: ubuntu-latest
        outputs:
            publish_results: ${{ steps.set.outputs.publish_results }}
        steps:
            - id: set
              run: |
                  echo "publish_results=${{
                    (github.event_name == 'workflow_dispatch' && github.event.inputs.publish_results == 'true') ||
                    (github.event_name == 'push' && github.ref_name == 'main')
                  }}" >> $GITHUB_OUTPUT
    #
    # Run benchmarks
    #
    benchmark:
        name: Run benchmarks (${{ matrix.os }})
        needs: prepare
        container: rustlang/rust:nightly
        runs-on: ${{ matrix.os }}
        strategy:
            fail-fast: false # make sure one matrix‐fail doesn’t stop the others
            matrix:
                os: [c7a-2xlarge, c8g-2xlarge, supermicro]
        steps:
            - name: Checkout Repository
              uses: actions/checkout@v5
              with:
                  fetch-depth: 0 # Fetch all history to include all git information in traces
            - name: Set safe directory
              # workaround: https://github.com/actions/checkout/issues/2031
              run: git config --global --add safe.directory "$GITHUB_WORKSPACE"
            - name: Setup Rust
              uses: actions-rust-lang/setup-rust-toolchain@v1
            - name: Execute Benchmarks
              run: |
                  ./scripts/run_benchmark.py \
                    --clean \
                    --output-dir benchmark_results \
                    --benchmark "${{ github.event.inputs.benchmark || 'all' }}"
            - name: Upload Results
              uses: actions/upload-artifact@v4
              with:
                  name: results-${{ matrix.os }}
                  path: benchmark_results
            - name: Prepare raw results for Bencher
              if: ${{ needs.prepare.outputs.publish_results == 'true' }}
              run: cp benchmark_results/all-results.json raw-results-${{ matrix.os }}.json
            - name: Upload raw results for Bencher
              if: ${{ needs.prepare.outputs.publish_results == 'true' }}
              uses: actions/upload-artifact@v4
              with:
                  name: upload-raw-results-${{ matrix.os }}
                  path: raw-results-${{ matrix.os }}.json
    #
    # Publish results to Bencher
    #
    publish_to_bencher:
        name: Publish Results to Bencher (${{ matrix.os }})
        if: ${{ needs.prepare.outputs.publish_results == 'true' && needs.benchmark.result == 'success' }}
        permissions:
            contents: read # allow reading repository contents
            checks: write # allow creating/updating check runs
        needs: [benchmark, prepare]
        runs-on: ubuntu-latest
        strategy:
            fail-fast: false
            matrix:
                # Using matrix to workaround Bencher's limitation of publishing checks for multiple machines
                os: [c7a-2xlarge, c8g-2xlarge, supermicro]
        steps:
            - name: Checkout Repository
              uses: actions/checkout@v5
            - name: Setup Bencher
              uses: bencherdev/bencher@v0.4.37 # Pin to specific version to avoid breaking changes
            - name: Download raw results for Bencher
              uses: actions/download-artifact@v4
              with:
                  pattern: upload-raw-results-${{ matrix.os }}
                  path: raw_results # directory for artifacts
                  merge-multiple: true # Merge multiple artifacts into a single directory
            - name: List results
              run: ls -lah raw_results/*
            - name: Convert raw to Bencher format
              run: |
                  mkdir -p output
                  ./scripts/convert_to_bencher.py \
                    "raw_results/raw-results-${{ matrix.os }}.json" \
                    "output/result.json"
            - name: Publish results to Bencher (${{ matrix.os }})
              env:
                  BENCHER_TOKEN: ${{ secrets.BENCHER_API_TOKEN }}
                  GHA_TOKEN: ${{ secrets.GITHUB_TOKEN }}
                  GIT_BRANCH: ${{ github.ref_name }}
                  MACHINE: ${{ matrix.os }}
              run: |
                  bencher run \
                    --project binius \
                    --token "${BENCHER_TOKEN}" \
                    --branch "${GIT_BRANCH}" \
                    --testbed "${MACHINE}" \
                    --threshold-measure latency \
                    --threshold-test t_test \
                    --threshold-max-sample-size 64 \
                    --threshold-upper-boundary 0.99 \
                    --thresholds-reset \
                    --err \
                    --adapter json \
                    --github-actions "${GHA_TOKEN}" \
                    --file "output/result.json"
            - name: Upload artifact
              uses: actions/upload-artifact@v4
              if: ${{ matrix.os == 'c7a-2xlarge' }}
              with:
                  name: gh-pages
                  path: output/
    #
    # Publish results to GH Pages
    #
    publish_to_gh_pages:
        name: Publish Results to Github Page
        if: ${{ github.ref_name == 'main' && needs.prepare.outputs.publish_results == 'true' }}
        permissions:
            contents: write
        needs: [prepare, publish_to_bencher]
        runs-on: ubuntu-latest
        steps:
            - name: Download artifact
              uses: actions/download-artifact@v4
              with:
                  name: gh-pages
            - name: Deploy to GitHub Pages
              uses: crazy-max/ghaction-github-pages@v4
              with:
                  repo: irreducibleoss/binius-benchmark
                  fqdn: benchmark.binius.xyz
                  target_branch: main
                  build_dir: ./
              env:
                  GITHUB_TOKEN: ${{ secrets.GH_TOKEN }}

    #
    # Upload perfetto traces to s3
    #
    upload_perfetto_traces:
        name: Upload Perfetto Traces to S3
        permissions:
            contents: read # allow reading repository contents
            checks: write # allow creating/updating check runs
            id-token: write # Required to get AWS credentials with OIDC
        needs: [benchmark, prepare]
        runs-on: ubuntu-latest
        outputs:
            s3_prefix: ${{ steps.upload.outputs.s3_prefix }}
            s3_path_filter: ${{ steps.upload.outputs.s3_path_filter }}
        steps:
            - name: Download Prefetto Traces
              uses: actions/download-artifact@v4
              with:
                  pattern: results-*
                  path: benchmark_results # directory for artifacts
            - name: List results
              run: ls -lah benchmark_results/*

            - name: Set up Python 3
              uses: actions/setup-python@v5
              with:
                  python-version: 3.13
            - name: Configure AWS Credentials
              uses: aws-actions/configure-aws-credentials@v4
              with:
                  aws-region: us-west-2
                  role-to-assume: ${{ secrets.AWS_UPLOAD_ROLE }}
            - name: Upload Perfetto Traces
              id: upload
              run: |
                  python3 - <<'EOF'
                  import os, glob, subprocess, urllib.parse, datetime

                  perfetto_host   = "https://perfetto.irreducible.com"
                  s3_bucket       = "${{ secrets.PERFETTO_BUCKET }}"
                  repo            = "${{ github.repository }}".split("/",1)[1]
                  branch          = "${{ github.ref_name }}".replace("/", "-")
                  sha             = "${{ github.sha }}"[:7]
                  run_dir         = f"{datetime.datetime.now(datetime.UTC):%Y-%m-%d_%H-%M-%S}-{sha}"
                  gh_summary_path = os.environ["GITHUB_STEP_SUMMARY"]
                  gh_output_path  = os.environ["GITHUB_OUTPUT"]

                  traces_by_benchmark = {}

                  # find & upload
                  for fp in sorted(glob.glob("benchmark_results/**/*.perfetto-trace", recursive=True)):
                      fn = os.path.basename(fp)
                      machine = os.path.basename(os.path.dirname(fp)).removeprefix("results-")
                      parts = fn.split("-", 4)
                      bm, mode, _, run_id, _ = parts
                      thread = mode + "-thread"

                      s3_key = f"traces/{repo}/{branch}/{bm}/{thread}/{machine}/{run_dir}/{machine}-{fn}"
                      subprocess.run(["aws", "s3", "cp", fp, f"{s3_bucket}/{s3_key}"], check=True)

                      trace_url       = f"{perfetto_host}/{s3_key}"
                      perfetto_ui_url = f"{perfetto_host}/#!/?url={urllib.parse.quote_plus(trace_url)}"

                      traces_by_benchmark.setdefault(bm, {}).setdefault(f"{bm} ({thread}) on {machine}", []).append(
                        f"<a href='{perfetto_ui_url}' target='_blank'>#{run_id}</a>"
                      )

                  # Write Summary to GitHub
                  with open(gh_summary_path, "a") as summary:
                    summary.write("## 📊 Perfetto Traces\n")
                    for bm, traces_by_group in traces_by_benchmark.items():
                      summary.write(f"<details><summary>{bm}</summary>\n<ul>\n")
                      for group_name, traces in traces_by_group.items():
                        summary.write(f"<li>{group_name} ")
                        summary.write(", ".join(traces))
                        summary.write("</li>\n")
                      summary.write("</ul>\n</details>\n")

                  # Expose outputs for the next step
                  with open(gh_output_path, "a") as f:
                    f.write(f"s3_prefix=traces/{repo}/{branch}\n")
                    f.write(f"s3_path_filter={run_dir}\n")

                  EOF

    #
    # Trigger Perfetto Trace Processor
    #
    trigger_perfetto_trace_processor:
        name: Trigger Perfetto Trace Processor
        needs: [upload_perfetto_traces]
        runs-on: ubuntu-latest
        steps:
            - name: Create GitHub App Token
              uses: actions/create-github-app-token@v2
              id: app-token
              with:
                app-id: ${{ vars.TRACE_PROCESSOR_APP_ID }}
                private-key: ${{ secrets.TRACE_PROCESSOR_APP_PRIVATE_KEY }}
                repositories: perfetto-trace-processor

            - name: Trigger process-benchmark for newly uploaded traces
              uses: peter-evans/repository-dispatch@v3
              with:
                token:       ${{ steps.app-token.outputs.token }}
                repository:  IrreducibleOSS/perfetto-trace-processor
                event-type:  process-benchmark
                client-payload: |
                  {
                    "s3_prefix":      "${{ needs.upload_perfetto_traces.outputs.s3_prefix }}",
                    "s3_path_filter": "${{ needs.upload_perfetto_traces.outputs.s3_path_filter }}"
                  }
